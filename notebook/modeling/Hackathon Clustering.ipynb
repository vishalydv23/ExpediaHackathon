{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook is inspired from https://www.kaggle.com/fabiendaniel/customer-segmentation\n",
    "\n",
    "With our data ready to be clustered from the notebook HackathonEDA. We can start clustering the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "data = pd.read_csv(\"../../data/processed/tempDataFrameLandmark/ratefinalData2ndCheckpoint.csv\")\n",
    "data = data.drop(['Unnamed: 0'], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating clusters of counties with high number of tourist per population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I will group the counties based on how popular they are in tourism considering their overall population. We will start with good old <b>kmeans</b> clustering. But before that, lets create a new dataframe that contains the values of tourism out of the complete data that has been prepared. We are interested in following fields. \n",
    "\n",
    "* lodgingInventoryBucketNonVacationalRental\n",
    "* lodgingInventoryBucketVacationalRental\n",
    "* lIBNonVRRatioToPopulation\n",
    "* lIBVRRatioToPopulation\n",
    "* aIPBRatioToPopulation\n",
    "* AERAFEmployementRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourismByCounty = data.filter(['lodgingInventoryBucketNonVacationalRental', 'lodgingInventoryBucketVacationalRental', 'lIBNonVRRatioToPopulation', 'lIBVRRatioToPopulation', 'aIPBRatioToPopulation', 'AERAFEmployementRatio'], axis=1)\n",
    "tourismByCounty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define (approximately) the number of clusters that best represents the data, I use the <b>silhouette score</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "matrix = tourismByCounty.as_matrix()\n",
    "for n_clusters in tqdm(range(3,10)):\n",
    "    kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=30)\n",
    "    kmeans.fit(matrix)\n",
    "    clusters = kmeans.predict(matrix)\n",
    "    silhouette_avg = silhouette_score(matrix, clusters)\n",
    "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
    "    if(n_clusters % 10 == 0):\n",
    "        unique, counts = np.unique(clusters, return_counts=True)\n",
    "        print(\"Minimum values in cluster is: \" , min(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score for 3 clusters is best but this will be very less of a cluster. Let's group the values in 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "silhouette_avg = -1\n",
    "while silhouette_avg < 0.3199:\n",
    "    kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=30)\n",
    "    kmeans.fit(matrix)\n",
    "    clusters = kmeans.predict(matrix)\n",
    "    silhouette_avg = silhouette_score(matrix, clusters)\n",
    "    \n",
    "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Characterizing the content of clusters</b>\n",
    "\n",
    "Number of elements in each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(clusters, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Silhouette intra-cluster score</b>\n",
    "\n",
    "In order to have an insight on the quality of the classification, we can represent the silhouette scores of each element of the different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_component_silhouette(n_clusters, lim_x, mat_size, sample_silhouette_values, clusters):\n",
    "    plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
    "    #____________________________\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(10, 8)\n",
    "    ax1.set_xlim([lim_x[0], lim_x[1]])\n",
    "    ax1.set_ylim([0, mat_size + (n_clusters + 1) * 10])\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        #___________________________________________________________________________________\n",
    "        # Aggregate the silhouette scores for samples belonging to cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[clusters == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        cmap = cm.get_cmap(\"Spectral\")\n",
    "        color = cmap(float(i) / n_clusters)        \n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values,\n",
    "                           facecolor=color, edgecolor=color, alpha=0.8)\n",
    "        #____________________________________________________________________\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.03, y_lower + 0.5 * size_cluster_i, str(i), color = 'red', fontweight = 'bold',\n",
    "                bbox=dict(facecolor='white', edgecolor='black', boxstyle='round, pad=0.3'))\n",
    "        #______________________________________\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#____________________________________\n",
    "# define individual silouhette scores\n",
    "sample_silhouette_values = silhouette_samples(matrix, clusters)\n",
    "#__________________\n",
    "# and do the graph\n",
    "graph_component_silhouette(n_clusters, [-0.4, 0.7], len(tourismByCounty), sample_silhouette_values, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at what each cluster and what is in them. And Rank clusters which attract more tourist per population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "clusterScore = {}\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    county_cluster = tourismByCounty.loc[clusters == i]\n",
    "    clusterScore[i] = (county_cluster['lIBNonVRRatioToPopulation'].mean() + \n",
    "                           county_cluster['lIBVRRatioToPopulation'].mean() + \n",
    "                           county_cluster['aIPBRatioToPopulation'].mean() + \n",
    "                           county_cluster['AERAFEmployementRatio'].mean()) / len(county_cluster)\n",
    "    \n",
    "sorted_d = dict( sorted(clusterScore.items(), key=operator.itemgetter(1),reverse=True))\n",
    "print('Dictionary in descending order by value : ',sorted_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the cluster number to the counties in main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.loc[:, 'tourismCluster'] = clusters\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first county with highest tourism per population i.e counties in cluster 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['tourismCluster'] == 3].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the county: Denali Borough in Alaska. And Denali National Park is Alaskaâ€™s most popular land attraction. Source: https://www.alaska.org/destination/denali-national-park\n",
    "\n",
    "Which proves that clustering done by our algorithm is quite nice. Here is a image of this beautiful county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"../../data/raw/Images/denali.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'../../data/processed/tempDataFrameLandmark/dataWithTourismCluster.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering of counties based on positive Economic social impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will cluster the counties that are bringing positive economic impact to the society. Following are the fields that we are going to use to do clustering.\n",
    "* medianHouseHoldIncome\n",
    "* unEmployementRate\n",
    "* vacantHousingUnitsRatio\n",
    "* familiesUnderPovertyScale\n",
    "* totalEmployedInOwnBusinesRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling median household income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medianHouseHoldIncome'] = (data['medianHouseHoldIncome'] / max(data['medianHouseHoldIncome'])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "economicsByCounties = data.filter(['medianHouseHoldIncome', 'unEmployementRate', 'vacantHousingUnitsRatio', 'familiesUnderPovertyScale', 'totalEmployedInOwnBusinesRate'], axis=1)\n",
    "economicsByCounties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data encoding</b>\n",
    "The different variables I selected have quite different ranges of variation and before continuing the analysis, I create a matrix where these data are standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "matrix = economicsByCounties.as_matrix()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(matrix)\n",
    "print('variables mean values: \\n' + 90*'-' + '\\n' , scaler.mean_)\n",
    "scaled_matrix = scaler.transform(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# matrix = economicsByCounties.as_matrix()\n",
    "for n_clusters in tqdm(range(3,10)):\n",
    "    kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=30)\n",
    "    kmeans.fit(scaled_matrix)\n",
    "    clusters = kmeans.predict(scaled_matrix)\n",
    "    silhouette_avg = silhouette_score(scaled_matrix, clusters)\n",
    "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
    "    if(n_clusters % 10 == 0):\n",
    "        unique, counts = np.unique(clusters, return_counts=True)\n",
    "        print(\"Minimum values in cluster is: \" , min(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a jump till cluster 5 and then the silhouette score starts to drop. So lets take 5 as the cluster size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "silhouette_avg = -1\n",
    "while silhouette_avg < 0.255:\n",
    "    kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=30)\n",
    "    kmeans.fit(scaled_matrix)\n",
    "    clusters = kmeans.predict(scaled_matrix)\n",
    "    silhouette_avg = silhouette_score(scaled_matrix, clusters)\n",
    "    \n",
    "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Characterizing the content of clusters</b>\n",
    "\n",
    "Number of elements in each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(clusters, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Silhouette intra-cluster score</b>\n",
    "\n",
    "In order to have an insight on the quality of the classification, we can represent the silhouette scores of each element of the different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_silhouette_values = silhouette_samples(scaled_matrix, clusters)\n",
    "#____________________________________\n",
    "# define individual silouhette scores\n",
    "sample_silhouette_values = silhouette_samples(scaled_matrix, clusters)\n",
    "#__________________\n",
    "# and do the graph\n",
    "graph_component_silhouette(n_clusters, [-0.2, 0.6], len(scaled_matrix), sample_silhouette_values, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at what each cluster and what is in them. And Rank clusters which attract more tourist per population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterScore = {}\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    county_cluster = economicsByCounties.loc[clusters == i]\n",
    "    clusterScore[i] = (county_cluster['medianHouseHoldIncome'].mean() - \n",
    "                           county_cluster['unEmployementRate'].mean() - \n",
    "                           county_cluster['vacantHousingUnitsRatio'].mean() - \n",
    "                           county_cluster['familiesUnderPovertyScale'].mean() + \n",
    "                           county_cluster['familiesUnderPovertyScale'].mean()) / len(county_cluster)\n",
    "    \n",
    "sorted_d = dict( sorted(clusterScore.items(), key=operator.itemgetter(1),reverse=True))\n",
    "print('Dictionary in descending order by value : ',sorted_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the value  to the main dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,'economicsCluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[(data['tourismCluster'] == 0) & (data['economicsCluster'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'../../data/processed/tempDataFrameLandmark/dataWithEconomicCluster.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering of counties based on positive Cultural social impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will cluster the counties that are bringing positive cultural impact to the society. Following are the fields that we are going to use to do clustering.\n",
    "* minorityPopulationRatio\n",
    "* structureBuiltYearBefore1939Ratio\n",
    "* CustomerSatisfactionAvgReviewRating\n",
    "* CustomerSatisfactionAvgStarRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cultureByCounties = data.filter(['minorityPopulationRatio', 'structureBuiltYearBefore1939Ratio', 'CustomerSatisfactionAvgReviewRating', 'CustomerSatisfactionAvgStarRating'], axis=1)\n",
    "cultureByCounties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data encoding</b>\n",
    "The different variables I selected have quite different ranges of variation and before continuing the analysis, I create a matrix where these data are standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "matrix = cultureByCounties.as_matrix()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(matrix)\n",
    "print('variables mean values: \\n' + 90*'-' + '\\n' , scaler.mean_)\n",
    "scaled_matrix = scaler.transform(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = economicsByCounties.as_matrix()\n",
    "for n_clusters in tqdm(range(3,10)):\n",
    "    kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=30)\n",
    "    kmeans.fit(scaled_matrix)\n",
    "    clusters = kmeans.predict(scaled_matrix)\n",
    "    silhouette_avg = silhouette_score(scaled_matrix, clusters)\n",
    "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
    "    if(n_clusters % 10 == 0):\n",
    "        unique, counts = np.unique(clusters, return_counts=True)\n",
    "        print(\"Minimum values in cluster is: \" , min(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
