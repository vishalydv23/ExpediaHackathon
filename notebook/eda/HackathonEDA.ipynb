{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "### Using the available information, we need you to identify clusters of accommodation that bring the most positive impact to the community, allowing a wider range of actors to participate in travel and tourism as consumers and/or providers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main dataset is yet to be released by the contest organizers. Meanwhile we can look at the secondary data. We assume that this data is collected to find out the factors that are considered to bring most positive impact on the society.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>We(Vishal/Shagun)</b> can simultaneously work on this notebook, under headings assigned to us.</span>\n",
    "\n",
    "<b> Note: \n",
    "    * Before pushing the code to the repo, always remember to clear the output first. Cell -> All Output -> clear.\n",
    "    * Document the code really well. This work style of working on same repo will help each other a lot if it is very well documented\n",
    "    * Always mention the exact data source giving the the url so that the other person can download it as we are not going to push the data to the repo. \n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Official Data \n",
    "Main data of the problem is stored in the a tsv file called data.tsv. Let's read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "mainData = pd.read_csv(\"../../data/raw/official/data.tsv\", sep='\\t')\n",
    "\n",
    "mainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks about right. Let's do the data profiling to get an insight of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "\n",
    "profile = mainData.profile_report(title='mainData Profiling Report')\n",
    "profile.to_file(output_file=\"../../data/processed/mainData.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a profiling report could be very big, we can write the report in a html file and save in data/processed folder. Also, doing the same for other datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiling counties data\n",
    "countiesData = pd.read_csv(\"../../data/raw/official/counties.tsv\", sep='\\t')\n",
    "profile = countiesData.profile_report(title='countiesData Profiling Report')\n",
    "profile.to_file(output_file=\"../../data/processed/countiesData.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiling  population characteristics for US counties for a period of 2010 to 2018 data\n",
    "censusData = pd.read_csv(\"../../data/raw/official/cc-est2018-alldata/cc-est2018-alldata.csv\", encoding=\"ISO-8859-1\")\n",
    "profile = censusData.profile_report(title='censusData Profiling Report')\n",
    "profile.to_file(output_file=\"../../data/processed/censusData.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>air_outbound_popularity_bucket</b> is highly correlated with <b>air_inbound_popularity_bucket <span style=\"color:green\">(ρ = 0.9962258185)</span></b>. So we can drop air_outbound_popularity from the table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainData = mainData.drop(['air_outbound_popularity_bucket'], axis=1)\n",
    "mainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>countyfp</b> is the funny one. Although, the total number of counties in USA and each state matches the count but the values are assigned quite randomly.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of counties in 3 states by alphabatical order\n",
    "print(mainData.groupby('state_code')['countyfp'].nunique()[:3], '\\n')\n",
    "# Total number of counties in USA\n",
    "print(mainData.groupby('state_code')['countyfp'].nunique().sum(), '\\n')\n",
    "# values of countyfp for randomly selected 5 states.\n",
    "print(np.sort(mainData[mainData.state_code == 'VA'].countyfp.unique()))\n",
    "print(np.sort(mainData[mainData.state_code == 'AK'].countyfp.unique()))\n",
    "print(np.sort(mainData[mainData.state_code == 'RI'].countyfp.unique()))\n",
    "print(np.sort(mainData[mainData.state_code == 'TX'].countyfp.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have repeating values for the countyfp for each state. But this is not the case with <b>geoid</b>. <b>gioid</b> has unique values for all the counties ranging from 1001 to 56037. Also, similar to countyfp there is no obvious pattern in assigning the values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values of geoid for randomly selected 2 states.\n",
    "print(np.sort(mainData[mainData.state_code == 'AK'].geoid.unique()))\n",
    "print(np.sort(mainData[mainData.state_code == 'AL'].geoid.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>lodging_num_reviews_bucket</b> is highly correlated to <b>lodging_inventory_bucket <span style=\"color:green\">(ρ = 0.929536127)</span></b> and <b>lodging_popularity_bucket</b> is highly correlated to <b>lodging_num_reviews_bucket<span style=\"color:green\">(ρ = 0.9485770051)</span></b> . So we can drop both of these fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainData = mainData.drop(['lodging_num_reviews_bucket','lodging_popularity_bucket'], axis=1)\n",
    "mainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>state_code</b> and <b>statefp</b> are basically same thing. We can drop state_code as well for Analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainData = mainData.drop(['state_code'], axis=1)\n",
    "mainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>lodging_avg_review_rating, lodging_avg_star_rating</b> and <b>lodging_inventory_bucket</b> has 59.3%, 64.1% and 51.1% of the values missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the summary of the lodging_avg_review_rating for Vacation rental true and false\n",
    "nonVacationRentalReview = mainData[mainData.is_vacation_rental == 0].lodging_avg_review_rating\n",
    "vacationRentalReview = mainData[mainData.is_vacation_rental == 1].lodging_avg_review_rating\n",
    "print(\"Non Vacational Rental Review Summary:\", nonVacationRentalReview.describe())\n",
    "print(\"\\n Vacational Rental Review Summary:\", vacationRentalReview.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For <b>lodging_avg_review_rating</b> the distribution is very Gaussian like and low standard deviation from the mean. We see a difference in mean and standard deviation of review rating. So we can replace Nan for both values differently.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling Nan with mean for vacation and non vacation rental and then replacing the original column\n",
    "x = mainData.loc[mainData.is_vacation_rental == 0]['lodging_avg_review_rating'].fillna(3.9)\n",
    "x = pd.DataFrame({'lodging_avg_review_rating' : x})\n",
    "y = mainData.loc[mainData.is_vacation_rental == 1]['lodging_avg_review_rating'].fillna(4.5)\n",
    "y = pd.DataFrame({'lodging_avg_review_rating' : y})\n",
    "frames = [x, y]\n",
    "z = pd.concat(frames)\n",
    "# replacing the original lodging_avg_review_rating\n",
    "mainData['lodging_avg_review_rating'] = z.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do more for the left two fields than just replacing the value with mean. We can come back to them if these value will be needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Let's start building the features and final dataset that will be used for clustering. lets build the data county wise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving geoid to final dataset\n",
    "finalData = pd.DataFrame({'geoid' : np.sort(mainData.geoid.unique())})\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Satisfaction\n",
    "Customer satisfaction is the first feature we are going to add to the dataset. We can take <b>lodging_avg_review_rating, lodging_avg_star_rating</b> take as customer satisfaction. We have already filler the missing values in the lodging_avg_review_rating, so we can add that to the data set straight up. But the rating is given for different years in the main Dataset. Lets take the latest value and average the value for vacation rental and non vacation rental.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# initialize the value in new column with float value\n",
    "finalData['CustomerSatisfactionAvgReviewRating'] = 0.0\n",
    "\n",
    "# taking average of latest avg review rating for vacation rental and non vacation rental\n",
    "for index, value in tqdm(finalData['geoid'].items()):\n",
    "    finalData.CustomerSatisfactionAvgReviewRating[index] = mainData[mainData.geoid == finalData.loc[index]['geoid']][-2:]['lodging_avg_review_rating'].values.mean()\n",
    "    \n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regenerating the missing values of the <b>lodging_avg_star_rating</b> will be little trickier. <span style=\"color:red\">We need to apply a Machine Learning Algorithm to regenerate the value.</span>\n",
    "\n",
    "We are not interested in all the values, but in the latest ones. Let's start with creating a new dataframe with lesser values. Also, check if value is not NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking oly the latest values from the dataset\n",
    "StarData = mainData[(mainData.months == '2018-10,2018-11') & (mainData['lodging_avg_star_rating'].notnull())]\n",
    "StarData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features are not useful for machine learning, we can remove them from the dataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageStarData = StarData.drop(['statefp','countyfp','geoid','months'], axis=1)\n",
    "averageStarData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is all set to be worked on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train , test = train_test_split(averageStarData, test_size = 0.3)\n",
    "\n",
    "x_train = train.drop('lodging_avg_star_rating', axis=1)\n",
    "y_train = train['lodging_avg_star_rating']\n",
    "\n",
    "x_test = test.drop('lodging_avg_star_rating', axis = 1)\n",
    "y_test = test['lodging_avg_star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_scaled)\n",
    "\n",
    "x_test_scaled = scaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# taking a look at the error rate for different k values\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "rmse_val = [] #to store rmse values for different k\n",
    "for K in range(30):\n",
    "    K = K+1\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "    model.fit(x_train, y_train)  #fit the model\n",
    "    pred=model.predict(x_test) #make prediction on test set\n",
    "    error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
    "    rmse_val.append(error) #store rmse values\n",
    "    print('RMSE value for k= ' , K , 'is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the rmse values against k values\n",
    "curve = pd.DataFrame(rmse_val) #elbow curve \n",
    "curve.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE value decreases as we increase the k value. At <b>k= 23</b>, the <b>RMSE is approximately 0.2859</b>, and shoots up on further increasing the k value. We can safely say that k=23 will give us the best result in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsRegressor(n_neighbors = 23)\n",
    "model.fit(x_train, y_train)  #fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullStarData = mainData[(mainData.months == '2018-10,2018-11') & (mainData['lodging_avg_star_rating'].isnull())]\n",
    "nullStarData = nullStarData.reset_index(drop=True)\n",
    "nullaverageStarData = nullStarData.drop(['statefp','countyfp','geoid','months', 'lodging_avg_star_rating'], axis=1)\n",
    "\n",
    "# taking the mean of the missing values for the lodging_inventory_bucket and lodging_price_bucket \n",
    "mean1 = nullaverageStarData['lodging_inventory_bucket'].mean() \n",
    "mean2 = nullaverageStarData['lodging_price_bucket'].mean()\n",
    "\n",
    "nullaverageStarData['lodging_inventory_bucket'].fillna(mean1, inplace =True)\n",
    "nullaverageStarData['lodging_price_bucket'].fillna(mean2, inplace =True)\n",
    "\n",
    "test_scaled = scaler.fit_transform(nullaverageStarData)\n",
    "test = pd.DataFrame(test_scaled)\n",
    "#predicting on the test set and creating submission file\n",
    "predict = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the value in new column with float value\n",
    "finalData['CustomerSatisfactionAvgStarRating'] = 0.0\n",
    "\n",
    "# Adding the values of prediction from nullStarData and original data of not null values from StarData\n",
    "for index, value in tqdm(finalData['geoid'].items()):\n",
    "    if(value in nullStarData['geoid'].unique()): # value present in nullStarData\n",
    "        geoidsIndex = nullStarData.index[nullStarData['geoid'] == value].values # get all the indexes\n",
    "        for geoindex in geoidsIndex:\n",
    "            finalData.CustomerSatisfactionAvgStarRating[index] = predict[geoindex]\n",
    "    if(value in StarData['geoid'].unique()):\n",
    "        starRatings = StarData[StarData['geoid'] == value]['lodging_avg_star_rating'].values # get all the values\n",
    "        for starRating in starRatings:\n",
    "            finalData.CustomerSatisfactionAvgStarRating[index] = starRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this our second feature is also ready :-) Let's save the dataframe locally to pick from here when we restart the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData.to_csv(r'../../data/processed/tempDataFrameLandmark/finalDataCutomerSatisfaction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in finding out which counties have more number of tourist coming. Also, number of tourist per population is more important than number of tourists itself.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the field that give a good insight into this is <b>lodging_inventory_bucket</b>. Showing a bucket of number of properties. Let's create an indicator by dividing this value by the population of the county. So, lets first add the population of county in finalData."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do that let's add the State and County FP code in the finalData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating the column in finalData\n",
    "finalData['STATEFP'] = 0\n",
    "finalData['COUNTYFP'] = 0\n",
    "for index, geoid in tqdm(finalData.geoid.items()):\n",
    "    finalData['STATEFP'][index] = mainData[mainData['geoid'] == geoid]['statefp'].unique()[0]\n",
    "    finalData['COUNTYFP'][index] = mainData[mainData['geoid'] == geoid]['countyfp'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding total population in finalData\n",
    "finalData['totalPopulation'] = 0\n",
    "for index in tqdm(range(len(finalData))):\n",
    "    tempValue = censusData[(censusData['STATE'] == finalData['STATEFP'][index]) &\n",
    "                          (censusData['COUNTY'] == finalData['COUNTYFP'][index])]\n",
    "    finalData['totalPopulation'][index] = tempValue[tempValue['YEAR'] == 11]['TOT_POP'].values[0]\n",
    "    \n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearranging the column position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = finalData[['STATEFP', 'COUNTYFP', 'geoid', 'CustomerSatisfactionAvgReviewRating', 'CustomerSatisfactionAvgStarRating', 'totalPopulation']]\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add <b>lodging_inventory_bucket</b> into the finalData. But as can be seen below that there is a big difference in the sum value of lodging_inventory_bucket for vacational and non vacational rentals. So we should create two variables out of it instead of taking their average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('non vacational rental:',mainData[mainData.is_vacation_rental == 0]['lodging_inventory_bucket'].sum())\n",
    "print('vacational rental:',mainData[mainData.is_vacation_rental == 1]['lodging_inventory_bucket'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating data of lodging Inventory bucket for vacation rental and non vacation rental in two new columns\n",
    "finalData['lodgingInventoryBucketNonVacationalRental'] = 0.0\n",
    "finalData['lodgingInventoryBucketVacationalRental'] = 0.0\n",
    "for index, value in tqdm(finalData['geoid'].items()):\n",
    "    finalData.lodgingInventoryBucketNonVacationalRental[index] = mainData[(mainData.months == '2018-10,2018-11') & \n",
    "                                                                          (mainData['geoid'] == value ) & \n",
    "                                                                          (mainData['is_vacation_rental'] == 0)]['lodging_inventory_bucket'].values[0]\n",
    "    finalData.lodgingInventoryBucketVacationalRental[index] = mainData[(mainData.months == '2018-10,2018-11') & \n",
    "                                                                          (mainData['geoid'] == value ) & \n",
    "                                                                          (mainData['is_vacation_rental'] == 1)]['lodging_inventory_bucket'].values[0]\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some places can have more tourism from other place but we are more interested in number of tourist coming to the county with proportion to the total population. This will give us better understanding of social impact of tourism in counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData['lIBNonVRRatioToPopulation'] = finalData['lodgingInventoryBucketNonVacationalRental'] / finalData['totalPopulation']\n",
    "finalData['lIBVRRatioToPopulation'] = finalData['lodgingInventoryBucketVacationalRental'] / finalData['totalPopulation']\n",
    "\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once divided by the population. The values become really small. Lets scale them back to a scale from 0 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData['lIBNonVRRatioToPopulation'] = (finalData['lIBNonVRRatioToPopulation'] / max(finalData['lIBNonVRRatioToPopulation'])) * 100\n",
    "finalData['lIBVRRatioToPopulation'] = (finalData['lIBVRRatioToPopulation'] / max(finalData['lIBVRRatioToPopulation'])) * 100\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! fun fact, The county with highest value for <b>lIBNonVRRatioToPopulation</b> and <b>lIBVRRatioToPopulation</b> is San Juan County, Colorado. Which has a population of 613 and looks like a very touristic place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((finalData['lIBNonVRRatioToPopulation'] / max(finalData['lIBNonVRRatioToPopulation'])) * 100).nlargest(5))\n",
    "print(censusData[(censusData.STATE == (finalData.loc[300][0])) & (censusData.COUNTY == (finalData.loc[300][1]))].iloc[0]['STNAME'])\n",
    "print(censusData[(censusData.STATE == (finalData.loc[300][0])) & (censusData.COUNTY == (finalData.loc[300][1]))].iloc[0]['CTYNAME'])\n",
    "\n",
    "# picture of San Juan county\n",
    "# ref: https://www.uncovercolorado.com/wp-content/uploads/2018/12/Downtown-Silverton-San-Juan-County-Colorado-1280x640-1094x547.jpg\n",
    "from IPython.display import Image\n",
    "Image(\"../../data/raw/Images/San-Juan-County-Colorado.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very similar process can be applied on <b>air_inbound_popularity_bucket</b>. Although 87.1% of the values are 0 for this field. We take a mean for values vacational rental and non vacational rental. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating data of air inbound bucket\n",
    "finalData['airInboundPopularityBucket'] = 0.0\n",
    "for index, value in tqdm(finalData['geoid'].items()):\n",
    "    finalData.airInboundPopularityBucket[index] = mainData[(mainData.months == '2018-10,2018-11') & \n",
    "                                                           (mainData['geoid'] == value ) ]['air_inbound_popularity_bucket'].values.mean()\n",
    "\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a ratio to the population\n",
    "finalData['aIPBRatioToPopulation'] = finalData['airInboundPopularityBucket'] / finalData['totalPopulation']\n",
    "# and scaling back to values between 0 and 100\n",
    "finalData['aIPBRatioToPopulation'] = (finalData['aIPBRatioToPopulation'] / max(finalData['aIPBRatioToPopulation'])) * 100\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use some other dataset as well apart from one give officially. We can get the idea of tourism in the county by checking the number of people who are employed in Arts, Entertainment, recreation, accommodation and food services. We can use the Economics Census of 2018 as dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "economicsDataset = pd.read_csv(\"../../data/raw/EconomyCensus2018/ACSDP1Y2018.DP03_data_with_overlays_2020-01-01T183501.csv\")\n",
    "economicsDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some values of the targeted fields are 'N', let's replace that with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index,geoid in tqdm(economicsDataset['GEO_ID'].items()):\n",
    "    if(economicsDataset[economicsDataset['GEO_ID'] == geoid]['DP03_0043E'].values[0] == 'N'):\n",
    "        economicsDataset.loc[index,'DP03_0043E'] = '0'\n",
    "    if(economicsDataset[economicsDataset['GEO_ID'] == geoid]['DP03_0043PE'].values[0] == 'N'):\n",
    "        economicsDataset.loc[index,'DP03_0043PE'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# populating data people emplyed in tourism related industry\n",
    "finalData['AERAFEmployement'] = 0.0\n",
    "finalData['AERAFEmployementPercent'] = 0.0\n",
    "for index, value in tqdm(finalData['geoid'].items()):\n",
    "    if((int(math.log10(value))+1) == 4):\n",
    "        if(economicsDataset['GEO_ID'].str.contains('0500000US0' + str(value)).any()):\n",
    "            finalData.AERAFEmployement[index] = float(economicsDataset[economicsDataset['GEO_ID'] == ('0500000US0' + str(value))]['DP03_0043E'].values[0])\n",
    "            finalData.AERAFEmployementPercent[index] = float(economicsDataset[economicsDataset['GEO_ID'] == ('0500000US0' + str(value))]['DP03_0043PE'].values[0])\n",
    "    elif((int(math.log10(value))+1) == 5):\n",
    "        if(economicsDataset['GEO_ID'].str.contains('0500000US' + str(value)).any()):\n",
    "            finalData.AERAFEmployement[index] = float(economicsDataset[economicsDataset['GEO_ID'] == ('0500000US' + str(value))]['DP03_0043E'].values[0])\n",
    "            finalData.AERAFEmployementPercent[index] = float(economicsDataset[economicsDataset['GEO_ID'] == ('0500000US' + str(value))]['DP03_0043PE'].values[0])\n",
    "        \n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73% of the values are missing. We can come back to fixing these missing values later. for now, we can  mark a check point here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData.to_csv(r'../../data/processed/tempDataFrameLandmark/finalData2ndCheckpoint.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Economic impact\n",
    "### Vishal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tourism affect the economy of the region and same holds for vice versa. In this section of the notebook we will try to analyze economic factor that impact community and hence tourism. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Income, Employment and Pay Gap</h4>\n",
    "Starting with income of people in the region. Better average income of the society indicate more prosperity. let's start playing with the data we have related with the income. \n",
    "\n",
    "* Data used: SELECTED ECONOMIC CHARACTERISTICS, 2018: ACS 1-Year Estimates Data profiles\n",
    "* url: https://data.census.gov/cedsci/table?q=United%20States&g=0100000US,.050000&table=DP03&tid=ACSDP1Y2018.DP03&hidePreview=true&vintage=2018&lastDisplayedRow=144\n",
    "\n",
    "The data is stored in raw folder as a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with looking at the median household income. It will give a good insight economic state of the county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating data of median household income in county\n",
    "finalData['medianHouseHoldIncome'] = 0.0\n",
    "for index, value in tqdm(finalData['geoid'].items()):\n",
    "    if((int(math.log10(value))+1) == 4):\n",
    "        if(economicsDataset['GEO_ID'].str.contains('0500000US0' + str(value)).any()):\n",
    "            finalData.medianHouseHoldIncome[index] = int(economicsDataset[economicsDataset['GEO_ID'] == ('0500000US0' + str(value))]['DP03_0062E'].values[0])\n",
    "    elif((int(math.log10(value))+1) == 5):    \n",
    "        if(economicsDataset['GEO_ID'].str.contains('0500000US' + str(value)).any()):\n",
    "            finalData.medianHouseHoldIncome[index] = int(economicsDataset[economicsDataset['GEO_ID'] == ('0500000US' + str(value))]['DP03_0062E'].values[0])\n",
    "\n",
    "finalData.head()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another indicator that we can consider is percent of unemployed people in the county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating data of unemployement percent in the population\n",
    "finalData['unEmployementRate'] = 0.0\n",
    "for index, value in tqdm(finalData['geoid'].items()):\n",
    "    if((int(math.log10(value))+1) == 4):\n",
    "        if(economicsDataset['GEO_ID'].str.contains('0500000US0' + str(value)).any()):\n",
    "            finalData.unEmployementRate[index] = float(economicsDataset[economicsDataset['GEO_ID'] == ('0500000US0' + str(value))]['DP03_0009PE'].values[0])\n",
    "    elif((int(math.log10(value))+1) == 5):    \n",
    "        if(economicsDataset['GEO_ID'].str.contains('0500000US' + str(value)).any()):\n",
    "            finalData.unEmployementRate[index] = float(economicsDataset[economicsDataset['GEO_ID'] == ('0500000US' + str(value))]['DP03_0009PE'].values[0])\n",
    "\n",
    "finalData.head()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under economics of the county we are interested in seeing the percent of people in that county under poverty level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating data of unemployement percent in the population\n",
    "finalData['povertyRate'] = 0.0\n",
    "for index, value in tqdm(finalData['geoid'].items()):\n",
    "    if((int(math.log10(value))+1) == 4):\n",
    "        if(economicsDataset['GEO_ID'].str.contains('0500000US0' + str(value)).any()):\n",
    "            finalData.povertyRate[index] = float(economicsDataset[economicsDataset['GEO_ID'] == ('0500000US0' + str(value))]['DP03_0128PE'].values[0])\n",
    "    elif((int(math.log10(value))+1) == 5):    \n",
    "        if(economicsDataset['GEO_ID'].str.contains('0500000US' + str(value)).any()):\n",
    "            finalData.povertyRate[index] = float(economicsDataset[economicsDataset['GEO_ID'] == ('0500000US' + str(value))]['DP03_0128PE'].values[0])\n",
    "\n",
    "finalData.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are interested in looking at the gender pay-gap. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cultural impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the official census data, we can start by looking at the racial diversity of the county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of minority population to total population\n",
    "finalData['minorityPopulationRatio'] = 0.0\n",
    "for index in tqdm(range(len(finalData))):\n",
    "    tempValue = censusData[(censusData['STATE'] == finalData['STATEFP'][index]) &\n",
    "                          (censusData['COUNTY'] == finalData['COUNTYFP'][index])]\n",
    "    minorityPopulationSum = tempValue.loc[tempValue['YEAR'] == 11, ['BA_MALE','BA_FEMALE','IA_MALE','IA_FEMALE','AA_MALE','AA_FEMALE','NA_MALE','NA_FEMALE']].values[0].sum()\n",
    "    finalData['minorityPopulationRatio'][index] = minorityPopulationSum / (tempValue[tempValue['YEAR'] == 11]['TOT_POP'].values[0])\n",
    "    \n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rescale the minority PopulationRatio to 0-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData['minorityPopulationRatio'] = (finalData['minorityPopulationRatio'] / max(finalData['minorityPopulationRatio'])) * 100\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
