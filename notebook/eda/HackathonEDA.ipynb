{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "### Using the available information, we need you to identify clusters of accommodation that bring the most positive impact to the community, allowing a wider range of actors to participate in travel and tourism as consumers and/or providers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main dataset is yet to be released by the contest organizers. Meanwhile we can look at the secondary data. We assume that this data is collected to find out the factors that are considered to bring most positive impact on the society.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>We(Vishal/Shagun)</b> can simultaneously work on this notebook, under headings assigned to us.</span>\n",
    "\n",
    "<b> Note: \n",
    "    * Before pushing the code to the repo, always remember to clear the output first. Cell -> All Output -> clear.\n",
    "    * Document the code really well. This work style of working on same repo will help each other a lot if it is very well documented\n",
    "    * Always mention the exact data source giving the the url so that the other person can download it as we are not going to push the data.  \n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Official Data \n",
    "Main data of the problem is stored in the a tsv file called data.tsv. Let's read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "mainData = pd.read_csv(\"../../data/raw/official/data.tsv\", sep='\\t')\n",
    "\n",
    "mainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks about right. Let's do the data profiling to get an insight of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "\n",
    "profile = mainData.profile_report(title='mainData Profiling Report')\n",
    "profile.to_file(output_file=\"../../data/processed/mainData.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a profiling report could be very big, we can write the report in a html file and save in data/processed folder. Also, doing the same for other datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiling counties data\n",
    "countiesData = pd.read_csv(\"../../data/raw/official/counties.tsv\", sep='\\t')\n",
    "profile = countiesData.profile_report(title='countiesData Profiling Report')\n",
    "profile.to_file(output_file=\"../../data/processed/countiesData.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiling  population characteristics for US counties for a period of 2010 to 2018 data\n",
    "censusData = pd.read_csv(\"../../data/raw/official/cc-est2018-alldata/cc-est2018-alldata.csv\", encoding=\"ISO-8859-1\")\n",
    "profile = censusData.profile_report(title='censusData Profiling Report')\n",
    "profile.to_file(output_file=\"../../data/processed/censusData.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>air_outbound_popularity_bucket</b> is highly correlated with <b>air_inbound_popularity_bucket <span style=\"color:green\">(ρ = 0.9962258185)</span></b>. So we can drop air_outbound_popularity from the table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainData = mainData.drop(['air_outbound_popularity_bucket'], axis=1)\n",
    "mainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>countyfp</b> is the funny one. Although, the total number of counties in USA and each state matches the count but the values are assigned quite randomly.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of counties in 3 states by alphabatical order\n",
    "print(mainData.groupby('state_code')['countyfp'].nunique()[:3], '\\n')\n",
    "# Total number of counties in USA\n",
    "print(mainData.groupby('state_code')['countyfp'].nunique().sum(), '\\n')\n",
    "# values of countyfp for randomly selected 5 states.\n",
    "print(np.sort(mainData[mainData.state_code == 'VA'].countyfp.unique()))\n",
    "print(np.sort(mainData[mainData.state_code == 'AK'].countyfp.unique()))\n",
    "print(np.sort(mainData[mainData.state_code == 'RI'].countyfp.unique()))\n",
    "print(np.sort(mainData[mainData.state_code == 'TX'].countyfp.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have repeating values for the countyfp for each state. But this is not the case with <b>geoid</b>. <b>gioid</b> has unique values for all the counties ranging from 1001 to 56037. Also, similar to countyfp there is no obvious pattern in assigning the values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values of geoid for randomly selected 2 states.\n",
    "print(np.sort(mainData[mainData.state_code == 'AK'].geoid.unique()))\n",
    "print(np.sort(mainData[mainData.state_code == 'AL'].geoid.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>lodging_num_reviews_bucket</b> is highly correlated to <b>lodging_inventory_bucket <span style=\"color:green\">(ρ = 0.929536127)</span></b> and <b>lodging_popularity_bucket</b> is highly correlated to <b>lodging_num_reviews_bucket<span style=\"color:green\">(ρ = 0.9485770051)</span></b> . So we can drop both of these fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainData = mainData.drop(['lodging_num_reviews_bucket','lodging_popularity_bucket'], axis=1)\n",
    "mainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>state_code</b> and <b>statefp</b> are basically same thing. We can drop state_code as well for Analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainData = mainData.drop(['state_code'], axis=1)\n",
    "mainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>lodging_avg_review_rating, lodging_avg_star_rating</b> and <b>lodging_inventory_bucket</b> has 59.3%, 64.1% and 51.1% of the values missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the summary of the lodging_avg_review_rating for Vacation rental true and false\n",
    "nonVacationRentalReview = mainData[mainData.is_vacation_rental == 0].lodging_avg_review_rating\n",
    "vacationRentalReview = mainData[mainData.is_vacation_rental == 1].lodging_avg_review_rating\n",
    "print(\"Non Vacational Rental Review Summary:\", nonVacationRentalReview.describe())\n",
    "print(\"\\n Vacational Rental Review Summary:\", vacationRentalReview.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For <b>lodging_avg_review_rating</b> the distribution is very Gaussian like and low standard deviation from the mean. We see a difference in mean and standard deviation of review rating. So we can replace Nan for both values differently.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling Nan with mean for vacation and non vacation rental and then replacing the original column\n",
    "x = mainData.loc[mainData.is_vacation_rental == 0]['lodging_avg_review_rating'].fillna(3.9)\n",
    "x = pd.DataFrame({'lodging_avg_review_rating' : x})\n",
    "y = mainData.loc[mainData.is_vacation_rental == 1]['lodging_avg_review_rating'].fillna(4.5)\n",
    "y = pd.DataFrame({'lodging_avg_review_rating' : y})\n",
    "frames = [x, y]\n",
    "z = pd.concat(frames)\n",
    "# replacing the original lodging_avg_review_rating\n",
    "mainData['lodging_avg_review_rating'] = z.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do more for the left two fields than just replacing the value with mean. We can come back to them if these value will be needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Let's start building the features and final dataset that will be used for clustering. lets build the data county wise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving geoid to final dataset\n",
    "finalData = pd.DataFrame({'geoid' : np.sort(mainData.geoid.unique())})\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Satisfaction\n",
    "Customer satisfaction is the first feature we are going to add to the dataset. We can take <b>lodging_avg_review_rating, lodging_avg_star_rating</b> take as customer satisfaction. We have already filler the missing values in the lodging_avg_review_rating, so we can add that to the data set straight up. But the rating is given for different years in the main Dataset. Lets take the latest value and average the value for vacation rental and non vacation rental.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# initialize the value in new column with float value\n",
    "finalData['CustomerSatisfactionAvgReviewRating'] = 0.0\n",
    "\n",
    "# taking average of latest avg review rating for vacation rental and non vacation rental\n",
    "for index, value in tqdm(finalData['geoid'].items()):\n",
    "    finalData.CustomerSatisfactionAvgReviewRating[index] = mainData[mainData.geoid == finalData.loc[index]['geoid']][-2:]['lodging_avg_review_rating'].values.mean()\n",
    "    \n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regenerating the missing values of the <b>lodging_avg_star_rating</b> will be little trickier. We need to apply a Machine Learning Algorithm to regenerate the value.\n",
    "\n",
    "We are not interested in all the values, but in the latest ones. Let's start with creating a new dataframe with lesser values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Economic impact\n",
    "### Vishal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tourism affect the economy of the region and same holds for vice versa. In this section of the notebook we will try to analyze economic factor that impact community and hence tourism. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Income</h4>\n",
    "Starting with income of people in the region. Better average income of the society indicate more prosperity. let's start playing with the data we have related with the income. \n",
    "\n",
    "* Data used: SELECTED ECONOMIC CHARACTERISTICS, 2018: ACS 1-Year Estimates Data profiles\n",
    "* url: https://data.census.gov/cedsci/table?q=United%20States&g=0100000US,.050000&table=DP03&tid=ACSDP1Y2018.DP03&hidePreview=true&vintage=2018&lastDisplayedRow=144\n",
    "\n",
    "The data is stored in raw folder as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "import pandas as pd\n",
    "\n",
    "censusData = pd.read_csv(\"../../data/raw/Census2018/ACSDP1Y2018.DP03_data_with_overlays_2019-12-28T161853.csv\") \n",
    "\n",
    "censusData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the dataframe.\n",
    "censusData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to remember for later.\n",
    "* pay gap between genders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental impact\n",
    "### Shagun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
